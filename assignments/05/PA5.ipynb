{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W69yRiYcGLTG"
   },
   "source": [
    "# Programming Assingment 5 (PA5)\n",
    "**Strong Recommendation**: Please use google COLAB for running your code or use a device with available GPU. \n",
    "\n",
    "**Google COLAB**: Simply upload the assignment notebook to your google drive and open it with google COLAB. \n",
    "\n",
    "**Make sure to select GPU in the setting for COLAB**. That can be done by going to \n",
    "\n",
    "`runtime->change runtime type->Hardware Accelerator->GPU`\n",
    "\n",
    "\n",
    "\n",
    "## Part 1 - Multliclass Classification over images using CNN's over MNIST\n",
    "Setting some hyperparameters and making sure we have a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xshs2A53AdDw"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np \n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "\n",
    "\n",
    "# Set the device to use\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "## Hyperparameters\n",
    "num_epochs = 10\n",
    "num_classes = 10\n",
    "batch_size = 256\n",
    "\n",
    "## Fixing Random Seed for Reproducibility\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "\n",
    "#ASSERTS\n",
    "print(str(device))\n",
    "assert(\"cuda\" in str(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TdWwTtEFAw1V"
   },
   "source": [
    "### Loading MNIST\n",
    "Here we are loading the MNIST dataset. This dataset consists of 60,000 train data and 10,000 test data. \n",
    "\n",
    "Each data is 28-by-28 image which and labels are 0 to 9 (representing digits 0-9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HWX8PM2c_8j1"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# transforms to apply to the data\n",
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "# MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(root=\"./data\", train=True, transform=trans, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root=\"./data\", train=False, transform=trans)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True,num_workers=0)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False,num_workers=0)\n",
    "\n",
    "\n",
    "##ASSERTS\n",
    "assert(len(train_loader)*batch_size >= 60000)\n",
    "assert(len(test_loader)*batch_size >=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gz9EDqAZKpgj"
   },
   "source": [
    "### Building the network\n",
    "We want to have the following architecture\n",
    "\n",
    " \n",
    "\n",
    "1.   2D Convolutional Layer with 32 output channels, 5-by-5 kernel, and padding of size 2, activation function RELU\n",
    "2.   Maxpooling with 2-by-2 kernel and stride of size 2\n",
    "3.   2D Convolutional Layer with 64 output channels, 5-by-5 kernel, and padding of size 2, activation function RELU\n",
    "4.   Maxpooling with 2-by-2 kernel and stride of size 2\n",
    "5.   Fully connected Layer with output size 512 with RELU activation\n",
    "6.   Fully connected Layer with output of size 10 (**no activation function**)\n",
    "\n",
    "Input:\n",
    "0. Input is 28-by-28 image with only 1 channel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a_mkRNMGDFSH"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "### ACT1-ACT9:\n",
    "### Complete the code below based on the architecture described above\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d() #ACT1 \n",
    "        self.pool1 = nn.MaxPool2d() #ACT2\n",
    "        self.conv2 = nn.Conv2d() #ACT3\n",
    "        self.pool2 = nn.MaxPool2d() #ACT4\n",
    "\n",
    "        # ACT5 compute the size of the the input for the first fully connected layer\n",
    "        # You can track what happens to a 28-by-28 images when passes through the previous layers\n",
    "        # you will endup with 64 channels each of size x-by-x therefore \n",
    "        # the size of input is (64*x*x) - you need to compute x and fill the code below\n",
    "        self.size_linear =  #ACT5\n",
    "        self.fc1 = nn.Linear(self.size_linear, 512)\n",
    "        self.fc2 = #ACT6\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x=self.pool1(F.relu(self.conv1(x))) \n",
    "        x = #ACT7\n",
    "        x = x.view(-1, self.size_linear) \n",
    "        x = #ACT8\n",
    "        x = #ACT9\n",
    "        return x\n",
    "\n",
    "##ASSERT\n",
    "with torch.no_grad():\n",
    "    # making 100 random images 1 channel 28-by-28\n",
    "    a = torch.rand(100, 1, 28, 28)\n",
    "    test_net = Net()\n",
    "    #passing through network\n",
    "    b = test_net.forward(a)\n",
    "    # the output should have size (100,10)\n",
    "    assert(b.size() == (100, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tsylgFgaTA-6"
   },
   "source": [
    "### Building the trainer\n",
    "When we call \n",
    "\n",
    "```\n",
    "trainer.train(epochs)\n",
    "```\n",
    "trainer for *epcohs* times goes over all the data. It iterates over batches of data, passes it through network, computes the loss and the gradients and lets the optimizer (SGD in our) update the parameteres. Look at the next cell after this one to see how we instantiate a trainer.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-6WDlxjvGPL9"
   },
   "outputs": [],
   "source": [
    "### ACT10-ACT14 Please fill the code below (hint: all of them are one line)\n",
    "class Trainer():\n",
    "    def __init__(self,net=None, optim=None, loss_function=None):\n",
    "        self.net = net\n",
    "        self.optim = optim\n",
    "        self.loss_function = loss_function\n",
    "\n",
    "    def train(self,epochs):\n",
    "        losses = []\n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0.0\n",
    "            epoch_steps = 0\n",
    "            for data in train_loader:\n",
    "                \n",
    "                # Moving this batch to GPU\n",
    "                # Note that X has shape (batch_size, number of channels, height, width)\n",
    "                # which is equal to (256,1,28,28) since our default batch_size = 256 and \n",
    "                # the image has only 1 channel\n",
    "                X = data[0].to(device)\n",
    "                y = data[1].to(device)\n",
    "                \n",
    "                # ACT10-Zero the gradient in the optimizer i.e. self.optim\n",
    "                ACT10 \n",
    "\n",
    "                # ACT11-Getting the output of the Network\n",
    "                output = ACT11\n",
    "\n",
    "                # ACT12-Computing loss using loss function i.e. self.loss_function\n",
    "                loss = ACT12\n",
    "\n",
    "                # ACT13-compute gradients of parameteres (backpropagation)\n",
    "                ACT13 \n",
    "\n",
    "                # ACT14-Call the optimizer i.e. self.optim\n",
    "                ACT14 \n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "                epoch_steps += 1\n",
    "            # average loss of epoch\n",
    "            losses.append(epoch_loss/epoch_steps)\n",
    "            print(\"epoch [%d]: loss %.3f\"%(epoch+1,losses[-1]))\n",
    "        return losses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jVkDdKlYb_Md"
   },
   "source": [
    "### Training the network \n",
    "Let's find the right learning rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vC6nDWj-VABE"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "### ACT15 try different learning rates for SGD to see which one works (do not try learning rates greater than 1)\n",
    "### number of epochs is fixed do not change it\n",
    "### we want the last epoch loss to be less thant 0.03\n",
    "learning_rate = #ACT15\n",
    "\n",
    "net = Net()\n",
    "a = net.to(device)\n",
    "opt = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "trainer  = Trainer(net=net, optim=opt, loss_function=loss_function)\n",
    "\n",
    "losses = trainer.train(num_epochs)\n",
    "print(losses)\n",
    "\n",
    "###ASSERTS\n",
    "assert(losses[-1]<=0.03)\n",
    "assert(len(losses)==num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oVc4_MpfcyJT"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "### ACT16 plot the training loss (y-axis) vs epoch number (x-axis)\n",
    "### using the losses you computed in previous step\n",
    "ACT16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YyUi3-iUcUbW"
   },
   "source": [
    "### Accuracy of our network on test data\n",
    "As you will see we will get accuracy of >98% on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n3OJWFiudMO7"
   },
   "outputs": [],
   "source": [
    "err = 0\n",
    "tot = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        # ACT17 retrieve X and y for this batch from data and \n",
    "        # move it to GPU (hint: look at what we did in trainer)\n",
    "        X = ACT17\n",
    "        y = ACT17\n",
    "\n",
    "        # raw output of network for X\n",
    "        output = net(X)\n",
    "        \n",
    "        # let the maximum index be our predicted class\n",
    "        _, yh = torch.max(output, 1) \n",
    "\n",
    "        # tot will 10,000 at the end, total number of test data\n",
    "        tot += y.size(0)\n",
    "\n",
    "        ## ACT18 add to err number of missclassification, i.e. number of indices that \n",
    "        ## yh and y are not equal\n",
    "        ## note that y and yh are vectors of size = batch_size = (256 in our case)\n",
    "        err += ACT18\n",
    "\n",
    "print('Accuaracy of prediction on test digits: %5.2f%%' % (100-100 * err / tot))\n",
    "\n",
    "###ASSERTS\n",
    "assert((100 - 100 * err / tot) >= 98)\n",
    "assert(tot == 10 * 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Py6Udla5csm2"
   },
   "source": [
    "### Visualizing CNN layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n1dtXLKWMw-s"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### function for normalizing a 2d image (input type = numpy 2d array)\n",
    "def normalize_image(npimg):\n",
    "    npimg = (npimg - np.mean(npimg)) / np.std(npimg)\n",
    "    npimg = np.minimum(1, np.maximum(0, (npimg + 0.5)))\n",
    "    return npimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tz2zL6WRcyhM"
   },
   "source": [
    "#### Visualizing each filter seperately in the first layer\n",
    "\n",
    "* Our first layer was a 2d convolutional layer with 32 output channels and 5-by-5 kernel\n",
    "* Therefore we have 32 different learnt filters each has size (1,5,5) or equivalently each filter is a 5-by-5 array of weights \n",
    "* Let's look at this filter as a 5-by-5 grayscale image and plot it\n",
    "\n",
    "\n",
    "After running this cell, answer the following question:\n",
    "\n",
    "\n",
    "**ACT19**\n",
    "**briefly explain what these filters are detecting**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mk-j3Oi7EciB"
   },
   "outputs": [],
   "source": [
    "### ACT20\n",
    "### fill the code below\n",
    "### hint: start by looking at size of net.conv1.weight \n",
    "#print(net.conv1.weight.size())\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(32):\n",
    "    plt.subplot(4,8,i+1)\n",
    "    npimg = ACT20 #5-by-5 numpy array corresponding to i-th filter \n",
    "    npimg = normalize_image(npimg)\n",
    "    plt.imshow(npimg, cmap=\"gray\", vmin=0,v max=1)\n",
    "    plt.title(\"filter \" + str(i+1))\n",
    "    plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JZjzbmKokzJX"
   },
   "source": [
    "### Visualizing input after applying first layer\n",
    "\n",
    "\n",
    "*   First layer has 32 filters\n",
    "*   since padding is 2 and kernel is 5-by-5 each output channel will be agian 28-by-28\n",
    "* Let's visualize each of these 32 pictures for each of sample digits\n",
    "\n",
    "After running this cell, answer the following question:\n",
    "\n",
    "**ACT21**\n",
    "**briefly explain what these images represent**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MXW39ehKcRaz"
   },
   "outputs": [],
   "source": [
    "\n",
    "### picking one sample from each label for visualizing purposes\n",
    "sample_digits = dict()\n",
    "for data in train_loader:\n",
    "    for i in range(data[1].shape[0]):\n",
    "        if data[1][i].item() not in sample_digits.keys():\n",
    "            sample_digits[data[1][i].item()] = data[0][i]\n",
    "    if len(sample_digits.keys()) == 10:\n",
    "        break\n",
    "\n",
    "    \n",
    "for digit in range(10):\n",
    "    plt.figure()\n",
    "    data = sample_digits[digit]\n",
    "    npimg = data[0].numpy()\n",
    "    npimg = normalize_image(npimg)\n",
    "    plt.imshow(npimg, cmap=\"gray\", vmin=0, vmax=1)\n",
    "    plt.title(\"original image of digit %d\"%digit)\n",
    "    plt.axis(\"off\")\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        data = data.unsqueeze(0).to(device)\n",
    "        ### ACT22\n",
    "        ### data has shape (1,1,28,28)\n",
    "        ### pass the data to only layer conv1 and apply RELU activation (do not apply maxpooling)\n",
    "        ### the output should be tensor of size (1,32,28,28)\n",
    "        output = ACT22\n",
    "    \n",
    "    data_numpy = output.detach().cpu().numpy()\n",
    "    for i in range(32):\n",
    "        plt.subplot(4, 8, i + 1)\n",
    "        npimg = data_numpy[0,i]\n",
    "        npimg=normalize_image(npimg)\n",
    "        plt.imshow(npimg, cmap=\"gray\", vmin=0, vmax=1)\n",
    "        plt.title(\"output of filter \" + str(i + 1))\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "    ###ASSERTS\n",
    "    assert(data.size()==(1, 1, 28, 28))\n",
    "    assert(output.size()==(1, 32, 28, 28))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPCpLrmdLuMEM0dFW+BOsrq",
   "collapsed_sections": [],
   "name": "HW5-Part1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
